{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Scraping ArXiv for 25 research papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YY8dCjmOZ6GJ",
    "outputId": "9d0c7dd1-3f3b-472d-cb50-aa7baa44f564",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "def scrape_arxiv_papers(search_url, output_csv=\"arxiv_papers.csv\"):\n",
    "    \"\"\"\n",
    "    Scrapes ArXiv search results to extract research paper titles and PDF links.\n",
    "    \"\"\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to retrieve page.\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    papers = soup.find_all(\"li\", class_=\"arxiv-result\")\n",
    "\n",
    "    paper_data = []\n",
    "    for paper in papers:\n",
    "        title_tag = paper.find(\"p\", class_=\"title is-5 mathjax\")\n",
    "        title = title_tag.text.strip() if title_tag else \"N/A\"\n",
    "\n",
    "        pdf_link_tag = paper.find(\"p\", class_=\"list-title is-inline-block\")\n",
    "        pdf_link = \"N/A\"\n",
    "        if pdf_link_tag:\n",
    "            pdf_link_a = pdf_link_tag.find(\"a\", string=\"pdf\")\n",
    "            pdf_link = pdf_link_a[\"href\"] if pdf_link_a else \"N/A\"\n",
    "\n",
    "        if pdf_link!=\"N/A\" : paper_data.append([title, pdf_link])\n",
    "\n",
    "    with open(output_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Title\", \"PDF Link\"])\n",
    "        writer.writerows(paper_data)\n",
    "\n",
    "    print(f\"Saved {len(paper_data)} papers to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "search_url = \"https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=algorithms&terms-0-field=all&terms-1-operator=OR&terms-1-term=data+processing+&terms-1-field=all&terms-2-operator=OR&terms-2-term=machine+learning&terms-2-field=all&terms-3-operator=OR&terms-3-term=llm&terms-3-field=all&terms-4-operator=OR&terms-4-term=analytics&terms-4-field=all&classification-computer_science=y&classification-physics_archives=all&classification-statistics=y&classification-include_cross_list=exclude&date-filter_by=all_dates&date-year=&date-from_date=&date-to_date=&date-date_type=submitted_date&abstracts=show&size=25&order=-announced_date_first\"\n",
    "scrape_arxiv_papers(search_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pe3-F-kiKYiD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLei89zCKsEj",
    "outputId": "de04e078-f89a-4c03-8635-ad33db822854",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain\n",
    "!pip install -q langchain-community\n",
    "!pip install -q langchain-chroma\n",
    "!pip install -q langchain-huggingface\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q bs4\n",
    "!pip install -q rank_bm25\n",
    "!pip install -q huggingface_hub\n",
    "!pip install -q requests\n",
    "!pip install PyPDF2\n",
    "!pip install bert-score\n",
    "!pip install faiss-cpu\n",
    "!pip install networkx matplotlib \n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kxayMljLPhu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "def download_pdf_from_link(pdf_url, save_path):\n",
    "    print(\"Downloading PDF from the link...\")\n",
    "    response = requests.get(pdf_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as pdf_file:\n",
    "            pdf_file.write(response.content)\n",
    "        print(f\"PDF downloaded successfully and saved to {save_path}\")\n",
    "        return save_path\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download PDF. HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "\n",
    "def split_text_into_documents(text: str, chunk_size: int = 1000, overlap: int = 100):\n",
    "    splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=chunk_size, chunk_overlap=overlap)\n",
    "    chunks = splitter.split_text(text)\n",
    "    return [Document(page_content=chunk) for chunk in chunks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: LLM Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "def load_mistral_llm():\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
    "    llm =  HuggingFacePipeline(\n",
    "        pipeline=pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            max_new_tokens=1024,  \n",
    "            min_length=30\n",
    "        )\n",
    "    )\n",
    "    return llm, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "def load_llama_llm():\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "    model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: LLM Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnwtA4xolKWt",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "import torch\n",
    "import gc\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "mistral_llm, mistral_tokenizer = load_mistral_llm()\n",
    "llama_llm, llama_tokenizer = load_llama_llm()\n",
    "\n",
    "def setup_llm(model_name):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if model_name == \"MistralAI\":\n",
    "        return mistral_llm, mistral_tokenizer\n",
    "    elif model_name == \"Llama\":\n",
    "        return llama_llm, llama_tokenizer\n",
    "    elif model_name == \"BART-Base\":\n",
    "        bart_pipeline = pipeline(\n",
    "            \"summarization\",\n",
    "            model=\"facebook/bart-base\",\n",
    "            tokenizer=\"facebook/bart-base\",\n",
    "            max_length=512,\n",
    "            min_length=30,\n",
    "            device=0 if torch.cuda.is_available() else -1\n",
    "        )\n",
    "        pipe = HuggingFacePipeline(pipeline=bart_pipeline)\n",
    "        bart_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "        return pipe, bart_tokenizer\n",
    "    elif model_name == \"T5-Base\": \n",
    "        return HuggingFacePipeline(\n",
    "            pipeline=pipeline(\n",
    "                \"text2text-generation\",\n",
    "                model=\"google-t5/t5-base\",\n",
    "                tokenizer=\"google-t5/t5-base\",\n",
    "                max_length=512,  \n",
    "                min_length=100,   \n",
    "                device=0 if torch.cuda.is_available() else -1\n",
    "            )\n",
    "        ), AutoTokenizer.from_pretrained(\"google-t5/t5-base\")\n",
    "    elif model_name == \"BigBird\":\n",
    "        bigbird_pipeline = pipeline(\n",
    "            \"summarization\",\n",
    "            model=\"google/bigbird-pegasus-large-arxiv\",\n",
    "            tokenizer=\"google/bigbird-pegasus-large-arxiv\",\n",
    "            max_length=1024,  \n",
    "            min_length=30,\n",
    "            device=0 if torch.cuda.is_available() else -1\n",
    "        )\n",
    "        pipe = HuggingFacePipeline(pipeline=bigbird_pipeline)\n",
    "        bigbird_tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n",
    "        return pipe, bigbird_tokenizer\n",
    "    raise ValueError(f\"Unknown model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Building RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kp7Th24kmKLm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "class BM25Retriever:\n",
    "\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.corpus = [doc.page_content for doc in documents]\n",
    "\n",
    "        self.tokenize_corpus = [doc.split() for doc in self.corpus]\n",
    "\n",
    "        self.bm25 = BM25Okapi(self.tokenize_corpus)\n",
    "\n",
    "\n",
    "    def retrieve(self, query, k=5):\n",
    "\n",
    "        tokenized_query = query.split()\n",
    "\n",
    "        top_documents = self.bm25.get_top_n(tokenized_query, self.corpus, n=k)\n",
    "\n",
    "        return top_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kp5HugGQcj7T",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "def build_faiss(documents: list[Document]) -> FAISS:\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    \n",
    "    vector_store = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYdmjXWFtxca",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "class EnsembleRetriever:\n",
    "\n",
    "    def __init__(self, faiss_retriever, bm25_retriever):\n",
    "        self.faiss_retriever = faiss_retriever\n",
    "        self.bm25_retriever = bm25_retriever\n",
    "\n",
    "    def get_relevant_documents(self, query: str, k: int = 5):\n",
    "        faiss_count = len(self.faiss_retriever.index_to_docstore_id)\n",
    "        bm25_count = len(self.bm25_retriever.corpus)\n",
    "        adjusted_k = min(k, faiss_count, bm25_count)\n",
    "        faiss_docs =  self.faiss_retriever.similarity_search(query,k=adjusted_k)\n",
    "\n",
    "        bm25_docs = self.bm25_retriever.retrieve(query,k=adjusted_k)\n",
    "\n",
    "        combined = faiss_docs + bm25_docs\n",
    "\n",
    "        seen = set()\n",
    "        unique_docs = []\n",
    "        for doc in combined:\n",
    "            content = doc.page_content if isinstance(doc, Document) else doc\n",
    "\n",
    "            key = content[:60]\n",
    "\n",
    "            if key not in seen:\n",
    "                if isinstance(doc, str):\n",
    "                    doc = Document(page_content=doc)\n",
    "                unique_docs.append(doc)\n",
    "                seen.add(key)\n",
    "\n",
    "        return unique_docs[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3r_YDxMozMZQ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def format_docs(docs):\n",
    "    if not docs:\n",
    "        return \"No relevant context found\"\n",
    "\n",
    "    snippet_list = []\n",
    "\n",
    "    for i, doc in enumerate(docs):\n",
    "\n",
    "      content = doc.page_content.strip().replace(\"\\n\",\" \").replace(\"\\r\", \" \")\n",
    "      snippet_list.append(f\"{i+1}. {content}\")\n",
    "\n",
    "    return \"\\n\".join(snippet_list)\n",
    "\n",
    "\n",
    "style_prompt = PromptTemplate(\n",
    "    input_variables=[\"style\", \"context\", \"original_text\"],\n",
    "    template=\"\"\"\n",
    "    Summarize the following text in a {style} style:\n",
    "    Context: {context}\n",
    "    Original Text: {original_text}\n",
    "    Summary:\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbvH2EZ9zp-d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import time\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def chunk_text(text, chunk_size=2000, overlap=200):\n",
    "    \"\"\"Splits text into overlapping chunks for summarization.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "def build_rag_chain(llm, tokenizer, faiss_retriever, bm25_retriever):\n",
    "\n",
    "    ensemble_retriever = EnsembleRetriever(faiss_retriever=faiss_retriever,bm25_retriever=bm25_retriever)\n",
    "\n",
    "    def retrieve_and_format_context(query, k=5):\n",
    "        context_docs =  ensemble_retriever.get_relevant_documents(query,k=k)\n",
    "\n",
    "        context = format_docs(context_docs)\n",
    "        return context\n",
    "\n",
    "    def rag_chain(inputs, model_name):\n",
    "        question = inputs[\"question\"]\n",
    "        style = inputs[\"style\"]\n",
    "        context = retrieve_and_format_context(question)\n",
    "\n",
    "        if not context:\n",
    "            print(f\"{model_name}: No valid context, returning empty summary\")\n",
    "            return \"\"\n",
    "\n",
    "        max_input_tokens = 400 if model_name == \"T5-Base\" else 2048 if model_name==\"BigBird\" else 700\n",
    "        if tokenizer is not None:\n",
    "            tokens = tokenizer(context, return_tensors=\"pt\", truncation=False)\n",
    "            token_count = tokens.input_ids.shape[1]\n",
    "            max_token_id = tokens.input_ids.max().item()\n",
    "            if max_token_id >= tokenizer.vocab_size:\n",
    "                return \"\"\n",
    "            if token_count > max_input_tokens:\n",
    "                tokens = tokens.input_ids[:, :max_input_tokens]\n",
    "                context = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "            token_count = tokenizer(context, return_tensors=\"pt\").input_ids.shape[1]\n",
    "            \n",
    "        if \"T5\" in model_name:\n",
    "            prompt_template = \"summarize: {context}\\n\\nQuestion: {question}\\nStyle: {style}\"\n",
    "        else:\n",
    "            prompt_template = \"{context}\\n\\nQuestion: {question}\\nStyle: {style}\"\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\", \"style\"],\n",
    "            template=prompt_template\n",
    "        ).format(context=context, question=question, style=style)\n",
    "\n",
    "        if tokenizer is not None:\n",
    "            tokens = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_input_tokens)\n",
    "            final_tokens = tokens.input_ids.shape[1]\n",
    "            max_token_id = tokens.input_ids.max().item()\n",
    "            if max_token_id >= tokenizer.vocab_size:\n",
    "                return \"\"\n",
    "            prompt = tokenizer.decode(tokens.input_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        time.sleep(10)\n",
    "        try:\n",
    "            if model_name == \"MistralAI\":\n",
    "                # Extract generated text for Mistral\n",
    "                result = llm.invoke(prompt)\n",
    "                if isinstance(result, list) and result:\n",
    "                    result = result[0].get(\"generated_text\", \"\")\n",
    "                elif isinstance(result, dict):\n",
    "                    result = result.get(\"generated_text\", \"\")\n",
    "            else:\n",
    "                result = llm.invoke(prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"{model_name} Invoke Failed: {str(e)}\")\n",
    "            return \"\"\n",
    "        return result\n",
    "\n",
    "    return rag_chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Extracting Methodology Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkLzWWR6w0tI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def convert_pdf_to_text(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def extract_methodology_section(text):\n",
    "    methodology_patterns = [\n",
    "        r\"(?i)\\b(methodology|methods|materials and methods|study design|experimental setup|approach)\\b\"\n",
    "    ]\n",
    "    methodology_start = None\n",
    "\n",
    "    for pattern in methodology_patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            methodology_start = match.start()\n",
    "            break\n",
    "\n",
    "    if methodology_start is None:\n",
    "        return \"No Methodology section found.\"\n",
    "\n",
    "    text_after_methodology = text[methodology_start:]\n",
    "\n",
    "    end_section_patterns = [\n",
    "        r\"(?i)\\n(results|discussion|conclusion|acknowledgments|references)\\b\"\n",
    "    ]\n",
    "    for pattern in end_section_patterns:\n",
    "        end_match = re.search(pattern, text_after_methodology)\n",
    "        if end_match:\n",
    "            return text_after_methodology[:end_match.start()].strip()\n",
    "\n",
    "    return text_after_methodology.strip()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: DAG Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xw0ShggR5w8_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def clean_node_name(name):\n",
    "    \"\"\"\n",
    "    Clean node names by removing special characters, normalizing spaces, and stripping.\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return str(name)\n",
    "    name = name.strip()\n",
    "    name = re.sub(r'\\s+', ' ', name)\n",
    "    return name\n",
    "\n",
    "def clean_category(category):\n",
    "    \"\"\"\n",
    "    Clean category names by normalizing spaces.\n",
    "    \"\"\"\n",
    "    if not isinstance(category, str):\n",
    "        return str(category)\n",
    "    category = category.strip()\n",
    "    category = re.sub(r'\\s+', ' ', category)\n",
    "    return category\n",
    "\n",
    "def is_ml_component(node_name, category):\n",
    "    \"\"\"\n",
    "    Determine if a node is an ML component based on name and category.\n",
    "    Excludes paper sections like 'Introduction', 'Results', etc.\n",
    "    \"\"\"\n",
    "    non_ml_keywords = {'introduction', 'results', 'conclusion', 'discussion', 'abstract', 'related work'}\n",
    "    node_name_lower = node_name.lower()\n",
    "    category_lower = category.lower()\n",
    "    return not any(keyword in node_name_lower for keyword in non_ml_keywords) and \\\n",
    "           not any(keyword in category_lower for keyword in non_ml_keywords)\n",
    "\n",
    "def extract_json_block(text):\n",
    "    \"\"\"\n",
    "    Extract the first valid JSON block from text by iteratively parsing substrings.\n",
    "    Handles nested JSON structures and common formatting issues.\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    start_indices = [i for i, char in enumerate(text) if char == '{']\n",
    "    if not start_indices:\n",
    "        return None\n",
    "\n",
    "    for start_idx in start_indices:\n",
    "        brace_count = 0\n",
    "        candidate = \"\"\n",
    "        for idx in range(start_idx, len(text)):\n",
    "            char = text[idx]\n",
    "            candidate += char\n",
    "            if char == '{':\n",
    "                brace_count += 1\n",
    "            elif char == '}':\n",
    "                brace_count -= 1\n",
    "                if brace_count == 0:\n",
    "                    try:\n",
    "                        # Clean common JSON issues\n",
    "                        cleaned_candidate = candidate\n",
    "                        cleaned_candidate = re.sub(r'//.*?\\n|/\\*.*?\\*/', '', cleaned_candidate, flags=re.DOTALL)  # Remove comments\n",
    "                        cleaned_candidate = re.sub(r',\\s*([\\]\\}])', r'\\1', cleaned_candidate)  # Remove trailing commas\n",
    "                        cleaned_candidate = cleaned_candidate.replace(\"'\", '\"')  # Replace single quotes\n",
    "                        cleaned_candidate = re.sub(r'([{,\\s])(\\w+)(?=\\s*:)', r'\\1\"\\2\"', cleaned_candidate)  # Quote unquoted keys\n",
    "                        json.loads(cleaned_candidate)\n",
    "                        return cleaned_candidate\n",
    "                    except json.JSONDecodeError:\n",
    "                        break  # Try next start index if parsing fails\n",
    "    return None\n",
    "\n",
    "def extract_pipeline(summary):\n",
    "          \n",
    "    prompt = f\"\"\"\n",
    "          Given the following machine learning pipeline summary:{summary}\n",
    "            Format the pipeline as a directed acyclic graph (DAG) where:\n",
    "            Nodes represent Datasets, Data Processing Methods(if available any), Algorithms, and Evaluation Metrics and must contain name, inputs(edge coming from other nodes, [] if null), category only .\n",
    "            Edges represent the sequence of steps in the pipeline and should be a list which contains dictionary object of source and target string.\n",
    "            The output should be in a single JSON structure containing all nodes and edges.\n",
    "          \"\"\"\n",
    "    model, tokenizer =  setup_llm(\"Llama\")\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1500,\n",
    "        do_sample=True,\n",
    "        temperature=0.3 \n",
    "    )\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    json_str = extract_json_block(result)\n",
    "    print(\"Json String\", json_str)\n",
    "    if not json_str:\n",
    "        print(\"No valid JSON block found in LLM output\")\n",
    "        return {\"nodes\": [], \"edges\": []}\n",
    "\n",
    "    try:\n",
    "        dag = json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing failed: {str(e)}\")\n",
    "        lines = json_str.splitlines()\n",
    "        error_line = min(len(lines), max(1, 1))\n",
    "        return {\"nodes\": [], \"edges\": []}\n",
    "\n",
    "    # Normalize DAG keys\n",
    "    normalized_dag = {}\n",
    "    for key, value in dag.items():\n",
    "        normalized_key = key.lower()\n",
    "        if normalized_key in ['nodes', 'node']:\n",
    "            normalized_dag['nodes'] = value\n",
    "        elif normalized_key in ['edges', 'edge']:\n",
    "            normalized_dag['edges'] = value\n",
    "\n",
    "    if 'nodes' not in normalized_dag:\n",
    "        normalized_dag['nodes'] = []\n",
    "    if 'edges' not in normalized_dag:\n",
    "        normalized_dag['edges'] = []\n",
    "\n",
    "    if not isinstance(normalized_dag['nodes'], list):\n",
    "        normalized_dag['nodes'] = []\n",
    "    if not isinstance(normalized_dag['edges'], list):\n",
    "        normalized_dag['edges'] = []\n",
    "\n",
    "    cleaned_nodes = []\n",
    "    for node in normalized_dag['nodes']:\n",
    "        if not isinstance(node, dict) or 'name' not in node:\n",
    "            continue\n",
    "        node['name'] = clean_node_name(node['name'])\n",
    "        node['category'] = clean_category(node.get('category', 'Unknown'))\n",
    "        if not is_ml_component(node['name'], node['category']):\n",
    "            continue\n",
    "        cleaned_nodes.append(node)\n",
    "    \n",
    "    normalized_dag['nodes'] = cleaned_nodes\n",
    "    node_names = set(node['name'] for node in normalized_dag['nodes'])\n",
    "\n",
    "    cleaned_edges = []\n",
    "    for edge in normalized_dag['edges']:\n",
    "        if isinstance(edge, dict) and 'source' in edge and 'target' in edge:\n",
    "            source = clean_node_name(edge['source'])\n",
    "            target = clean_node_name(edge['target'])\n",
    "            if source in node_names and target in node_names:\n",
    "                cleaned_edges.append({\"source\": source, \"target\": target})\n",
    "\n",
    "    normalized_dag['edges'] = cleaned_edges\n",
    "\n",
    "    existing_edges = {(edge['source'], edge['target']) for edge in normalized_dag['edges']}\n",
    "    inferred_edges = []\n",
    "\n",
    "    for node in normalized_dag['nodes']:\n",
    "        node_name = node['name']\n",
    "        inputs = node.get('inputs', [])\n",
    "        for input_node in inputs:\n",
    "            cleaned_input = clean_node_name(input_node)\n",
    "            if cleaned_input in node_names and (cleaned_input, node_name) not in existing_edges:\n",
    "                inferred_edges.append({\n",
    "                    \"source\": cleaned_input,\n",
    "                    \"target\": node_name\n",
    "                })\n",
    "\n",
    "    normalized_dag['edges'].extend(inferred_edges)\n",
    "\n",
    "    valid_nodes = set(node['name'] for node in normalized_dag['nodes'])\n",
    "    normalized_dag['edges'] = [\n",
    "        edge for edge in normalized_dag['edges']\n",
    "        if edge['source'] in valid_nodes and edge['target'] in valid_nodes\n",
    "    ]\n",
    "    return normalized_dag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Pipeline Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "def show_pipeline(graph_data):\n",
    "    try:\n",
    "        if 'nodes' not in graph_data or 'edges' not in graph_data:\n",
    "            print(\"Missing 'nodes' or 'edges' in graph data\")\n",
    "            return\n",
    "        \n",
    "        G = nx.DiGraph()\n",
    "        category_colors = {'Unknown': 'gray'}\n",
    "        color_cycle = cm.tab20(np.linspace(0, 1, 20))\n",
    "        color_index = 0\n",
    "\n",
    "        for node in graph_data['nodes']:\n",
    "            category = node.get('category', 'Unknown').rstrip('s')\n",
    "            if category and category != 'Unknown' and category not in category_colors:\n",
    "                if color_index < len(color_cycle):\n",
    "                    new_color = tuple(color_cycle[color_index])\n",
    "                    new_color_hex = f\"#{int(new_color[0]*255):02x}{int(new_color[1]*255):02x}{int(new_color[2]*255):02x}\"\n",
    "                    category_colors[category] = new_color_hex\n",
    "                    color_index += 1\n",
    "                else:\n",
    "                    new_color = f\"#{np.random.randint(0, 255):02x}{np.random.randint(0, 255):02x}{np.random.randint(0, 255):02x}\"\n",
    "                    category_colors[category] = new_color\n",
    "\n",
    "\n",
    "        for node in graph_data['nodes']:\n",
    "            node_id = node.get('name')\n",
    "            if not node_id:\n",
    "                continue\n",
    "            category = node.get('category', 'Unknown').rstrip('s')\n",
    "            display_label = (node_id[:30] + '...') if len(node_id) > 30 else node_id\n",
    "            G.add_node(node_id, category=category, label=display_label)\n",
    "\n",
    "        for edge in graph_data['edges']:\n",
    "            source = edge.get('source')\n",
    "            target = edge.get('target')\n",
    "            if source and target:\n",
    "                G.add_edge(source, target)\n",
    "    \n",
    "        node_colors = [category_colors.get(G.nodes[node].get('category', 'Unknown'), 'gray') for node in G.nodes]\n",
    "\n",
    "        def get_node_levels(G):\n",
    "            levels = {}\n",
    "            def assign_level(node, level):\n",
    "                if node not in levels or level > levels[node]:\n",
    "                    levels[node] = level\n",
    "                    for successor in G.successors(node):\n",
    "                        assign_level(successor, level + 1)\n",
    "            for node in G.nodes:\n",
    "                if G.in_degree(node) == 0:\n",
    "                    assign_level(node, 0)\n",
    "            return levels\n",
    "\n",
    "        levels = get_node_levels(G)\n",
    "        pos = {}\n",
    "        max_level = max(levels.values()) if levels else 0\n",
    "        for node in G.nodes:\n",
    "            level = levels.get(node, 0)\n",
    "            nodes_at_level = [n for n in G.nodes if levels.get(n, 0) == level]\n",
    "            x = len(nodes_at_level)\n",
    "            x_pos = nodes_at_level.index(node) / max(1, x - 1) if x > 1 else 0.5\n",
    "            y_pos = 1 - (level / max_level) if max_level > 0 else 0.5\n",
    "            pos[node] = (x_pos, y_pos)\n",
    "\n",
    "        plt.figure(figsize=(15, 12))\n",
    "        nx.draw(\n",
    "            G,\n",
    "            pos,\n",
    "            with_labels=True,\n",
    "            labels={node: G.nodes[node].get('label', node) for node in G.nodes},\n",
    "            node_color=node_colors,\n",
    "            node_size=4000,\n",
    "            font_size=8,\n",
    "            font_weight='bold',\n",
    "            edge_color='gray',\n",
    "            arrowsize=20\n",
    "        )\n",
    "\n",
    "        legend_labels = {category: plt.Line2D([0], [0], marker='o', color='w', label=category,\n",
    "                                              markerfacecolor=color, markersize=10)\n",
    "                         for category, color in category_colors.items()}\n",
    "        plt.legend(handles=legend_labels.values(), title=\"Node Categories\", loc='best')\n",
    "\n",
    "        plt.title(\"Hierarchical Pipeline DAG Visualization\", fontsize=14, pad=20)\n",
    "        plt.savefig('hierarchical_graph.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Plot not available due to {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: BERTScore Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OitsZnDnR0h0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import datetime\n",
    "import platform\n",
    "from bert_score import score\n",
    "\n",
    "\n",
    "def evaluate_bert_score(methodology_section, summaries):\n",
    "  torch.manual_seed(42)\n",
    "  scores = {}\n",
    "  model_type = \"roberta-large\"\n",
    "  original_text = methodology_section\n",
    "\n",
    "  for model, summary in summaries.items():\n",
    "    P, R, F1 = score([summary], [original_text], model_type=model_type)\n",
    "    summary_scores = {\n",
    "        \"Precision\": round(P.item(), 4),\n",
    "        \"Recall\": round(R.item(), 4),\n",
    "        \"F1 Score\": round(F1.item(), 4)\n",
    "    }\n",
    "    scores[model] = summary_scores\n",
    "\n",
    "  best_model = max(scores, key=lambda k: scores[k][\"F1 Score\"])\n",
    "  best_summary = summaries[best_model]\n",
    "  print(f\"Best Model: {best_model}\")\n",
    "  print(f\"Score: {scores[best_model]}\")\n",
    "  return best_model, best_summary, scores[best_model]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Summary Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPdo-s5UHB-E",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def generate_summary(faiss_retriever,bm25_retriever):\n",
    "  summaries = {}\n",
    "  model_names = [\"T5-Base\", \"MistralAI\", \"BART-Base\", \"BigBird\"]\n",
    "  for model_name in model_names:\n",
    "        print(f\"Running {model_name}...\")\n",
    "        llm,tokenizer = setup_llm(model_name)\n",
    "        rag_chain = build_rag_chain(llm=llm, tokenizer=tokenizer, faiss_retriever=faiss_retriever, bm25_retriever=bm25_retriever)\n",
    "        user_text = \"Summarize the research paper, focusing on which and how the algorithms, datasets, data analytics methods, and evaluation metrics used, excluding references. Do not return the content as it is return the summary\"\n",
    "        target_style = \"in format of paragraph summary of around 500 words\"\n",
    "        inputs = {\"question\": user_text, \"style\": target_style, \"original_text\": user_text}\n",
    "        try:\n",
    "            styled_result = rag_chain(inputs, model_name)\n",
    "        except Exception as e:\n",
    "            print(f\"{model_name} Failed: {str(e)}\")\n",
    "            styled_result = \"\"\n",
    "        summaries[model_name] = styled_result\n",
    "\n",
    "        if model_name != \"MistralAI\":\n",
    "            del llm\n",
    "            if tokenizer is not None:\n",
    "                del tokenizer\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "  return summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10: Pipeline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from networkx.algorithms.similarity import graph_edit_distance\n",
    "\n",
    "def compute_normalized_levenshtein(ref_nodes, gen_nodes):\n",
    "\n",
    "    similarities = []\n",
    "    \n",
    "    ref_nodes_by_category = {}\n",
    "    gen_nodes_by_category = {}\n",
    "    for node in ref_nodes:\n",
    "        category = clean_category(node.get('category', 'Unknown'))\n",
    "        ref_nodes_by_category.setdefault(category, []).append(node)\n",
    "    for node in gen_nodes:\n",
    "        category = clean_category(node.get('category', 'Unknown'))\n",
    "        gen_nodes_by_category.setdefault(category, []).append(node)\n",
    "    \n",
    "    for category in ref_nodes_by_category:\n",
    "        ref_cat_nodes = ref_nodes_by_category.get(category, [])\n",
    "        gen_cat_nodes = gen_nodes_by_category.get(category, [])\n",
    "        if not gen_cat_nodes:\n",
    "            continue\n",
    "        \n",
    "        for ref_node in ref_cat_nodes:\n",
    "            best_similarity = 0\n",
    "            best_match = None\n",
    "            ref_name = clean_node_name(ref_node['name'])\n",
    "            \n",
    "            for gen_node in gen_cat_nodes:\n",
    "                gen_name = clean_node_name(gen_node['name'])\n",
    "                lev_distance = levenshtein_distance(ref_name, gen_name)\n",
    "                max_length = max(len(ref_name), len(gen_name))\n",
    "                normalized_distance = lev_distance / max_length if max_length > 0 else 0\n",
    "                similarity = 1 - normalized_distance\n",
    "                if similarity > best_similarity:\n",
    "                    best_similarity = similarity\n",
    "                    best_match = gen_name\n",
    "            \n",
    "            if best_match:\n",
    "                similarities.append(best_similarity)\n",
    "    \n",
    "    return np.mean(similarities) if similarities else 0.0\n",
    "\n",
    "\n",
    "bert_model = SentenceTransformer('all-MPNet-base-v2')\n",
    "\n",
    "def normalize_node_labels(graph):\n",
    "   \n",
    "    nodes = graph['nodes']\n",
    "    name_map = {}\n",
    "    \n",
    "    for node in nodes:\n",
    "        name = node['name']\n",
    "        if name in name_map:\n",
    "            continue\n",
    "        for other_node in nodes:\n",
    "            if other_node['name'] in name_map:\n",
    "                continue\n",
    "            if node['name'] != other_node['name']:\n",
    "                similarity = util.cos_sim(\n",
    "                    bert_model.encode(node['name']),\n",
    "                    bert_model.encode(other_node['name'])\n",
    "                ).item()\n",
    "                if similarity > 0.9:  \n",
    "                    name_map[other_node['name']] = name\n",
    "    \n",
    "    for node in nodes:\n",
    "        if node['name'] in name_map:\n",
    "            node['name'] = name_map[node['name']]\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def filter_non_pipeline_nodes(graph):\n",
    "    pipeline_categories = {'Dataset', 'DataProcessing', 'Algorithm', 'EvaluationMetric'}\n",
    "    filtered_nodes = [\n",
    "        node for node in graph['nodes']\n",
    "        if node.get('category') in pipeline_categories\n",
    "    ]\n",
    "    \n",
    "    filtered_node_names = {node['name'] for node in filtered_nodes}\n",
    "    for node in filtered_nodes:\n",
    "        node['inputs'] = [inp for inp in node['inputs'] if inp in filtered_node_names]\n",
    "    \n",
    "    return {'nodes': filtered_nodes}\n",
    "\n",
    "def create_nx_graph(dag):\n",
    "    G = nx.DiGraph()\n",
    "    for node in dag['nodes']:\n",
    "        G.add_node(node['name'], label=node['name'], category=node.get('category', 'Unknown'))\n",
    "    for node in dag['nodes']:\n",
    "        for input_name in node['inputs']:\n",
    "            if input_name in G.nodes:\n",
    "                G.add_edge(input_name, node['name'])\n",
    "    return G\n",
    "\n",
    "def approximate_ged(G1, G2):\n",
    "    nodes1 = list(G1.nodes(data=True))\n",
    "    nodes2 = list(G2.nodes(data=True))\n",
    "\n",
    "    sim_matrix = np.zeros((len(nodes1), len(nodes2)))\n",
    "    for i, (n1, d1) in enumerate(nodes1):\n",
    "        for j, (n2, d2) in enumerate(nodes2):\n",
    "            label_sim = util.cos_sim(\n",
    "                bert_model.encode(d1['label']),\n",
    "                bert_model.encode(d2['label'])\n",
    "            ).item()\n",
    "            category_sim = 1.0 if d1['category'] == d2['category'] else 0.5\n",
    "            sim_matrix[i, j] = label_sim * category_sim\n",
    "    \n",
    "    matched = set()\n",
    "    matches = []\n",
    "    for i in range(len(nodes1)):\n",
    "        if i >= len(nodes2):\n",
    "            break\n",
    "        j = np.argmax(sim_matrix[i, :])\n",
    "        if j not in matched and sim_matrix[i, j] > 0.5:\n",
    "            matches.append((nodes1[i][0], nodes2[j][0]))\n",
    "            matched.add(j)\n",
    "    \n",
    "    node_cost = len(nodes1) + len(nodes2) - 2 * len(matches)\n",
    "    edge_cost = 0\n",
    "    for u1, u2 in matches:\n",
    "        edges1 = set(G1.out_edges(u1)).union(G1.in_edges(u1))\n",
    "        edges2 = set(G2.out_edges(u2)).union(G2.in_edges(u2))\n",
    "        edge_cost += len(edges1.symmetric_difference(edges2))\n",
    "    \n",
    "    return node_cost + edge_cost\n",
    "\n",
    "def exact_ged(G1, G2):\n",
    "    def node_subst_cost(n1, n2):\n",
    "        label_sim = util.cos_sim(\n",
    "            bert_model.encode(n1['label']),\n",
    "            bert_model.encode(n2['label'])\n",
    "        ).item()\n",
    "        category_sim = 0.0 if n1['category'] == n2['category'] else 1.0\n",
    "        return 1.0 - label_sim + category_sim\n",
    "    \n",
    "    def node_del_cost(n):\n",
    "        return 1.0\n",
    "    \n",
    "    def node_ins_cost(n):\n",
    "        return 1.0\n",
    "    \n",
    "    def edge_subst_cost(e1, e2):\n",
    "        return 0.0 if e1 == e2 else 1.0\n",
    "    \n",
    "    def edge_del_cost(e):\n",
    "        return 1.0\n",
    "    \n",
    "    def edge_ins_cost(e):\n",
    "        return 1.0\n",
    "    \n",
    "    return nx.graph_edit_distance(\n",
    "        G1, G2,\n",
    "        node_subst_cost=node_subst_cost,\n",
    "        node_del_cost=node_del_cost,\n",
    "        node_ins_cost=node_ins_cost,\n",
    "        edge_subst_cost=edge_subst_cost,\n",
    "        edge_del_cost=edge_del_cost,\n",
    "        edge_ins_cost=edge_ins_cost\n",
    "    )\n",
    "\n",
    "def compute_ged(dag_pair):\n",
    "    dag1, dag2 = dag_pair\n",
    "    dag1 = normalize_node_labels(dag1)\n",
    "    dag2 = normalize_node_labels(dag2)\n",
    "    dag1 = filter_non_pipeline_nodes(dag1)\n",
    "    dag2 = filter_non_pipeline_nodes(dag2)\n",
    "    \n",
    "    G1 = create_nx_graph(dag1)\n",
    "    G2 = create_nx_graph(dag2)\n",
    "    \n",
    "    if len(G1.nodes) > 15 or len(G2.nodes) > 15:\n",
    "        return approximate_ged(G1, G2)\n",
    "    else:\n",
    "        return exact_ged(G1, G2)\n",
    "\n",
    "def evaluate_pipeline(ref_dag, gen_dag):\n",
    "    \n",
    "    ged = compute_ged((ref_dag, gen_dag))\n",
    "    levenshtein_similarity = compute_normalized_levenshtein(ref_dag['nodes'], gen_dag['nodes'])\n",
    "\n",
    "    return {\n",
    "        'ged': ged,\n",
    "        'levenshtein_similarity': levenshtein_similarity\n",
    "    }\n",
    "\n",
    "def visualize_evaluation(results):\n",
    "    \n",
    "    metrics = ['normalized_ged', 'levenshtein_similarity']\n",
    "    n_pipelines = len(results)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bar_width = 0.25\n",
    "    index = np.arange(n_pipelines)\n",
    "\n",
    "    x_labels = list(range(1, n_pipelines + 1))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        values = [r[4][metric] for r in results]\n",
    "        plt.bar(index + i * bar_width, values, bar_width, label=metric)\n",
    "    \n",
    "    plt.xlabel('Pipelines')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Pipeline Evaluation Metrics')\n",
    "    plt.xticks(index + bar_width, x_labels, rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('evaluation_metrics_ged_levenshtein.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"/kaggle/input/pipeline-extract/Pipeline_Dataset - Sheet1.csv\")\n",
    "    results = []\n",
    "    titles = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        title = row['Title']\n",
    "        content = row['Content']\n",
    "        ref_pipeline = json.loads(row['pipeline'])\n",
    "\n",
    "        all_docs = split_text_into_documents(content)\n",
    "        faiss_retriever = build_faiss(all_docs)\n",
    "        bm25_retriever = BM25Retriever(all_docs)\n",
    "        summaries = generate_summary(faiss_retriever,bm25_retriever)\n",
    "        best_model, best_summary, bert_score = evaluate_bert_score(content, summaries)\n",
    "        pipeline_generated = extract_pipeline(best_summary)\n",
    "        show_pipeline(pipeline_generated)\n",
    "        pipeline_evaluation = evaluate_pipeline(ref_pipeline, pipeline_generated)\n",
    "        results.append([title, best_summary, bert_score, pipeline_generated, pipeline_evaluation])\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "           \n",
    "        print(f\"Evaluation for '{title}':\")\n",
    "        print(json.dumps(pipeline_evaluation, indent=2))\n",
    "        \n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=[\"Title\", \"Summary\", \"BERTScore\", \"Pipeline\", \"PipelineEvaluation\"])\n",
    "    results_df.to_csv(\"results.csv\", index=False)\n",
    "    \n",
    "    avg_metrics = {\n",
    "        'normalized_ged': np.mean([r[4]['normalized_ged'] for r in results]),\n",
    "        'levenshtein_similarity': np.mean([r[4]['levenshtein_similarity'] for r in results]),\n",
    "    }\n",
    "    \n",
    "    print(\"\\nAverage Metrics Across Pipelines:\")\n",
    "    print(json.dumps(avg_metrics, indent=2))\n",
    "    \n",
    "    visualize_evaluation(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize_evaluation(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1pFwYzOCZvj",
    "outputId": "242a794e-3cbb-4b96-e8bb-0fc897f935e9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    df = pd.read_csv(\"arxiv_papers.csv\")\n",
    "    results = []\n",
    "    temp_pdf_path = \"research_paper.pdf\"\n",
    "    i=1\n",
    "\n",
    "    for _,row in df.iterrows():\n",
    "        title, pdf_url = row[\"Title\"], row[\"PDF Link\"]\n",
    "        print(f\"{i}. {title}\")\n",
    "        pdf_path = download_pdf_from_link(pdf_url,temp_pdf_path)\n",
    "        text = convert_pdf_to_text(pdf_path)\n",
    "        methodology_section = extract_methodology_section(text)\n",
    "        all_docs = split_text_into_documents(methodology_section)\n",
    "        faiss_retriever = build_faiss(all_docs)\n",
    "        bm25_retriever = BM25Retriever(all_docs)\n",
    "        summaries = generate_summary(faiss_retriever,bm25_retriever)\n",
    "        best_model, best_summary, bert_score = evaluate_bert_score(methodology_section, summaries)\n",
    "        formatted_summary = extract_pipeline(best_summary)\n",
    "        show_pipeline(formatted_summary)\n",
    "        results.append([title, pdf_url, best_model, best_summary, formatted_summary, bert_score])\n",
    "        i=i+1\n",
    "        if os.path.exists(temp_pdf_path):\n",
    "          os.remove(temp_pdf_path)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=[\"Title\", \"PDF Link\", \"Best Model\", \"Summary\", \"Pipeline\", \"BERTScore\"])\n",
    "    results_df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVj8_b5J-dM-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "\n",
    "pipeline_components = {\n",
    "    \"Datasets Used\": [\"COCO\", \"ImageNet\", \"MNIST\", \"CIFAR-10\", \"Pascal VOC\", \"UCI ML Repository\"],\n",
    "    \"Data Analytics Methods Applied\": [\"Principal Component Analysis (PCA)\", \"t-SNE for Visualization\",\n",
    "                                       \"Statistical Feature Selection\", \"Data Augmentation\", \"Anomaly Detection\"],\n",
    "    \"Algorithms Implemented\": [\"YOLOv12\", \"ResNet-50\", \"BERT Transformer\", \"XGBoost\", \"Random Forest\", \"LSTM Networks\"],\n",
    "    \"Evaluation Metrics Used\": [\"mAP@50-95\", \"F1-score\", \"Accuracy\", \"ROC-AUC\", \"Mean Squared Error (MSE)\"]\n",
    "}\n",
    "\n",
    "all_pipelines = list(itertools.product(*pipeline_components.values()))\n",
    "\n",
    "structured_pipelines = [\n",
    "    {\n",
    "        \"Datasets Used\": pipeline[0],\n",
    "        \"Data Analytics Methods Applied\": pipeline[1],\n",
    "        \"Algorithms Implemented\": pipeline[2],\n",
    "        \"Evaluation Metrics Used\": pipeline[3]\n",
    "    }\n",
    "    for pipeline in all_pipelines\n",
    "]\n",
    "\n",
    "with open(\"all_research_pipelines.json\", \"w\") as f:\n",
    "    json.dump(structured_pipelines, f, indent=4)\n",
    "\n",
    "for i, pipeline in enumerate(structured_pipelines[:5]):\n",
    "    print(f\"Pipeline {i+1}:\")\n",
    "    for step, method in pipeline.items():\n",
    "        print(f\"  {step}: {method}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(f\"Total Pipelines Generated: {len(structured_pipelines)}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6833845,
     "sourceId": 10981111,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7258039,
     "sourceId": 11634699,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
